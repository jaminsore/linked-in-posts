{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5c96dc",
   "metadata": {},
   "source": [
    "# Pickling and FastText models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481da30",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14d5c3",
   "metadata": {},
   "source": [
    "Here, we will import the necessary modules and define the convenience functions we will use throughout this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b63d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "from typing import Self, Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from lorem_text import lorem\n",
    "from fasttext import FastText\n",
    "from sklearn import pipeline, base, cluster\n",
    "\n",
    "\n",
    "def make_fake_data(n_samples: int = 100) -> list[str]:\n",
    "    return [lorem.sentence() for _ in range(n_samples)]\n",
    "\n",
    "\n",
    "def save_pipeline(pipeline: pipeline.Pipeline, filename: str = \"saved_pipeline.pkl\") -> None:\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "\n",
    "\n",
    "def load_pipeline(filename: str = \"saved_pipeline.pkl\") -> pipeline.Pipeline:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def train_model(corpus: list[str]) -> FastText._FastText:\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        data_file = pathlib.Path(d) / \"training_data.txt\"\n",
    "        data_file.write_text(\"\\n\".join(corpus) + \"\\n\")\n",
    "        model = FastText.train_unsupervised(str(data_file))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9c56f",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af848f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For the purposes of illustration, we are going to be making a clustering\n",
    "[Pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators)\n",
    "with two steps\n",
    "\n",
    "  1. a [FastText](https://fasttext.cc/) embedding transformer step\n",
    "  2. a [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) step\n",
    "\n",
    "We are then going to try to serliaize this `Pipeline` using Python's\n",
    "[pickle](https://docs.python.org/3/library/pickle.html) module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4914aa2",
   "metadata": {},
   "source": [
    "### Define the `FastTextTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a21b8",
   "metadata": {},
   "source": [
    "This is done by implementing the following:\n",
    "\n",
    "  1. inherit from [base.BaseEstimator](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn-base-baseestimator) and [base.TransformerMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn-base-transformermixin)\n",
    "  2. implement both `fit` and `transform` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, model: FastText._FastText):\n",
    "        self.model = model\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, *args: Any, **kwargs: Any) -> Self:\n",
    "        # No-Op\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        text = np.atleast_1d(X)\n",
    "\n",
    "        if text.ndim != 1:\n",
    "            raise ValueError(f\"`X` must be 1-dimensional, received {text.ndim}d data\")\n",
    "\n",
    "        return np.asarray([self.model.get_sentence_vector(s) for s in text.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41ba9a",
   "metadata": {},
   "source": [
    "### Train your FastText model and construct your clustering pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25fe3e",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_trainig_data = make_fake_data()\n",
    "fasttext_model = train_model(corpus=fasttext_trainig_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b3f7d",
   "metadata": {},
   "source": [
    "#### Train your cluster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a689204",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_training_data = make_fake_data()\n",
    "random_state = np.random.RandomState(1024)  # setting random state for comparability\n",
    "\n",
    "unpicklable_pipeline = pipeline.make_pipeline(\n",
    "    FastTextTransformer(model=fasttext_model), cluster.KMeans(n_clusters=2, n_init=\"auto\", random_state=random_state)\n",
    ").fit(cluster_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f0322",
   "metadata": {},
   "source": [
    "#### Save your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedc0df",
   "metadata": {},
   "source": [
    "Here we should get\n",
    "> `TypeError: cannot pickle 'fasttext_pybind.fasttext' object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(unpicklable_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6aa6b",
   "metadata": {},
   "source": [
    "### What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c6e9d",
   "metadata": {},
   "source": [
    "`fasttext_pybind.fasttext` is a compiled C++ extension and so cannot be serialized cross-platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924562ef",
   "metadata": {},
   "source": [
    "### Are we out of luck?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0687c",
   "metadata": {},
   "source": [
    "At this point we have two choices:\n",
    "\n",
    "  1. accept that we can't use `FastText` models in our pipeline transformations\n",
    "  2. learn some pickling dark magic, and make an object that we can pickle\n",
    "\n",
    "Option $1$ is no fun and wouldn't make for a very interesting post so let's go with option $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a51f7",
   "metadata": {},
   "source": [
    "### What can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66402d57",
   "metadata": {},
   "source": [
    "Fortunately, we have a couple things going for us.\n",
    "\n",
    "  1. `fasttext` provides its own `load_model` and `save_model` methods (see `model` [docs](https://fasttext.cc/docs/en/python-module.html#model-object))\n",
    "  2. Object pickling in Python, like most things, relies on a protocol that we are free to hack away at# %% [markdown]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ed15c",
   "metadata": {},
   "source": [
    "### The solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c54605",
   "metadata": {},
   "source": [
    "With this in mind, we simply wrap `fasttext.load_model` and\n",
    "`FastText._FastText.save_model` functionality with Python's pickling\n",
    "protocol. This requires us to extend `FastText._FastText` to include:\n",
    "\n",
    "1. a method to serialize a trained model to `bytes`\n",
    "3. a constructor to instantiate a model from its serialized `bytes` representatino\n",
    "2. override the [\\_\\_reduce\\_\\_](https://docs.python.org/3/library/pickle.html#object.__reduce__) method to return a `tuple` containing\n",
    "  > - A callable object that will be called to create the initial version of the object.\n",
    "  > - A tuple of arguments for the callable object. An empty tuple must be given if the callable does not accept any argument.\n",
    "\n",
    "In our case `__reduce__` will return a `tuple` containing the constructor in\n",
    "(2) and a `tuple` containing the `bytes` of our serialized instance returned\n",
    "from the method in (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be3b18",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a381a16",
   "metadata": {},
   "source": [
    "Finally, we land on the following implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tempfile\n",
    "from typing import Callable, Self\n",
    "\n",
    "import fasttext\n",
    "from fasttext import FastText\n",
    "\n",
    "\n",
    "class PicklableFastText(FastText._FastText):  # type: ignore[no-any-unimported]\n",
    "    _tmp_filename = \"model.bin\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model: FastText._FastText) -> Self:  # type: ignore[no-any-unimported]\n",
    "        self = cls.__new__(cls)\n",
    "        self.__dict__.update(model.__dict__)\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, saved_model: bytes | str) -> Self:\n",
    "        if isinstance(saved_model, str) and pathlib.Path(saved_model).exists():\n",
    "            return cls.from_pretrained(fasttext.load_model(saved_model))\n",
    "\n",
    "        if isinstance(saved_model, bytes):\n",
    "            with tempfile.TemporaryDirectory() as d:\n",
    "                model_path = pathlib.Path(d) / cls._tmp_filename\n",
    "                model_path.write_bytes(saved_model)\n",
    "                return cls.load(str(model_path))\n",
    "\n",
    "        raise FileNotFoundError(saved_model)\n",
    "\n",
    "    def serialize(self) -> bytes:\n",
    "        with tempfile.TemporaryDirectory() as d:\n",
    "            model_path = pathlib.Path(d) / self._tmp_filename\n",
    "            self.save_model(str(model_path))\n",
    "            return model_path.read_bytes()\n",
    "\n",
    "    def __reduce__(self) -> tuple[Callable[[bytes | str], Self], tuple[bytes]]:\n",
    "        return self.load, (self.serialize(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4083c",
   "metadata": {},
   "source": [
    "#### Update our original pipeline with our `PicklableFastText` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "picklable_pipeline = pipeline.make_pipeline(\n",
    "    FastTextTransformer(model=PicklableFastText.from_pretrained(fasttext_model)),\n",
    "    cluster.KMeans(n_clusters=2, n_init=\"auto\", random_state=random_state),\n",
    ").fit(cluster_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8231d9",
   "metadata": {},
   "source": [
    "#### Save our new Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba90e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(picklable_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d39db",
   "metadata": {},
   "source": [
    "#### Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92785b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sentence = lorem.sentence()\n",
    "\n",
    "print(picklable_pipeline.transform([sentence]))\n",
    "print(load_pipeline().transform([sentence]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
