{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86df726-1291-4fef-ae3b-f80c3e8a27ad",
   "metadata": {},
   "source": [
    "# Pickling and FastText models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e567d0e-d8d7-4bf5-8c4a-d4e02cef3230",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7c5b3-f2fc-455e-a3e2-fc1a36be5b82",
   "metadata": {},
   "source": [
    "Here, we will import the necessary modules and define the convenience functions we will use throughout this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f06ace-6153-4b9e-9fae-64a2e1f848ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline, preprocessing, base, cluster\n",
    "from typing import Self, Any\n",
    "from fasttext import FastText\n",
    "import numpy as np\n",
    "from lorem_text import lorem\n",
    "import tempfile\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "def make_fake_data(n_samples: int = 100) -> str:\n",
    "    return \"\\n\".join(lorem.sentence() for _ in range(n_samples)) + \"\\n\"\n",
    "\n",
    "\n",
    "def save_pipeline(pipeline: pipeline.Pipeline, filename: str = \"saved_pipeline.pkl\") -> None:\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "\n",
    "\n",
    "def load_pipeline(filename: str = \"saved_pipeline.pkl\") -> pipeline.Pipeline:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def train_model(n_examples: int = 100) -> FastText._FastText:\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        data_file = pathlib.Path(d) / \"training_data.txt\"\n",
    "        data_file.write_text(make_fake_data())\n",
    "        model = FastText.train_unsupervised(str(data_file))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351dcc9-042b-4a9e-ab59-212ae4b9283e",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df7bec-85ac-4c03-8593-2b4c9ecceb5a",
   "metadata": {},
   "source": [
    "Suppose you wanted to do some clustering using on some sentence embeddings taken from Meta's [FastText](https://fasttext.cc/) model, and you were a disciplined ML engineer who also wanted to use scikit-learn's well-known transformer interface (not to be confused with HuggingFace's `transformers`) so that you could drop it in a [Pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators). And, let's suppose that models are persisteed in your organization using [pickles](https://docs.python.org/3/library/pickle.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0280eb-e267-4434-bc51-75fd7b839bd5",
   "metadata": {},
   "source": [
    "### You define your`FastTextTransformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5305a2-1d0e-47c4-88b8-8e2dc622b6d7",
   "metadata": {},
   "source": [
    "This is done by implementing the following:\n",
    "  1. inherit from `base.BaseEstimator` and `base.TransformerMixin`\n",
    "  2. implement both `fit` and `transform` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223df4d5-1e07-4e24-8126-3112d4e67c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, model: FastText._FastText):\n",
    "        self.model = model\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, *args: Any, **kwargs: Any) -> Self:\n",
    "        # No-Op\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        text = np.atleast_1d(X)\n",
    "\n",
    "        if text.ndim != 1:\n",
    "            raise ValueError(f\"`X` must be 1-dimensional, received {text.ndim}d data\")\n",
    "\n",
    "        return np.asarray([self.model.get_sentence_vector(s) for s in text.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637d55c-bd92-4b2c-b4f9-33f107cbfa56",
   "metadata": {},
   "source": [
    "### Train your FastText model and construct your clustering pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92e899-0858-462a-8c1e-e4c8a8b22a55",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f3e68-59a6-4742-8997-56f9b7317054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9880a59a-2948-4456-8389-840eff872354",
   "metadata": {},
   "source": [
    "#### Train your cluster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe5c94-8e48-4a94-a1ab-7ecf9712cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_training_data = make_fake_data().strip().split(\"\\n\")\n",
    "random_state = np.random.RandomState(1024)  # setting random state for comparibility\n",
    "\n",
    "unpicklable_pipeline = pipeline.make_pipeline(\n",
    "    FastTextTransformer(model=fasttext_model), cluster.KMeans(n_clusters=2, n_init=\"auto\", random_state=random_state)\n",
    ").fit(cluster_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe885a-8c7a-4ef4-8c74-d170f4b77bab",
   "metadata": {},
   "source": [
    "#### Save your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f38a7-67e4-470e-9079-69e472f59f84",
   "metadata": {},
   "source": [
    "Here we should get\n",
    "> `TypeError: cannot pickle 'fasttext_pybind.fasttext' object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe60c3-8b3c-4a5b-b923-283637c8fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(unpicklable_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b47450-ae5b-40b4-bd37-4653de9082c3",
   "metadata": {},
   "source": [
    "### What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18127928-227a-4e5d-995e-300610a1f1bd",
   "metadata": {},
   "source": [
    "`fasttext_pybind.fasttext` is a compiled C++ extension and so cannot be serialized cross-platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70eb1fe-9d0e-441a-9a69-9f6a2ebb3a01",
   "metadata": {},
   "source": [
    "### Are we out of luck?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9076c9f-5d66-4310-87c7-8c4a83bd9954",
   "metadata": {},
   "source": [
    "At this point we have two choices:\n",
    "1. accept that we can't use `FastText` models in our pipeline transformations\n",
    "2. learn some pickling dark magic, and make an object that we can pickle\n",
    "\n",
    "Option $1$ is no fun and wouldn't make for a very interesting post so let's go with option $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c28e75-3466-46da-84f2-e7ee27ca5cdf",
   "metadata": {},
   "source": [
    "### What can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78daa69-600c-4a5d-8ce9-f2114909dcbf",
   "metadata": {},
   "source": [
    "Fortunately, we have a couple things going for us.\n",
    "1. `fasttext` provides its own object serialization functionality (see [fasttext.save_model]())\n",
    "2. Object pickling in Python, like most things, relies on a protocol that we are free to hack away at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8908bd0-e1c4-491d-a0e4-8cdde41cb768",
   "metadata": {},
   "source": [
    "### The solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208add75-a08b-41fb-8f16-ff92998b03af",
   "metadata": {},
   "source": [
    "The solution is simply wrap`fasttext.load_model` and `FastText._FastText.save_model` functionality into Python's pickling protocol. All this requires is us to extend `FastText._FastText` to include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110ff97-e51f-49fe-8cc3-43d73a3fe52c",
   "metadata": {},
   "source": [
    "1. a method to serialize a trained model to `bytes`\n",
    "3. a constructor to instantiate a model from its serialized `bytes` representatino\n",
    "2. override the [\\_\\_reduce\\_\\_](https://docs.python.org/3/library/pickle.html#object.__reduce__) method to return a `tuple` containing\n",
    "  > - A callable object that will be called to create the initial version of the object.\n",
    "  > - A tuple of arguments for the callable object. An empty tuple must be given if the callable does not accept any argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb50c2-84db-4cd2-a2ab-13b19bb9532e",
   "metadata": {},
   "source": [
    "In our case `__reduce__` will return a `tuple` containing the constructor in 2.) and a `tuple` containing the `bytes` of our serialized instance returned from the method in 1.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccecd85-fe3c-4340-9de1-dc533c0af55e",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c22c56-9381-416a-84b3-851947b887e7",
   "metadata": {},
   "source": [
    "Finally, we land on an implementation like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff69dd-e950-4b58-a2b3-17e65609925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tempfile\n",
    "from typing import Callable, Self\n",
    "\n",
    "import fasttext\n",
    "from fasttext import FastText\n",
    "\n",
    "\n",
    "class PicklableFastText(FastText._FastText):  # type: ignore[no-any-unimported]\n",
    "    _tmp_filename = \"model.bin\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model: FastText._FastText) -> Self:  # type: ignore[no-any-unimported]\n",
    "        self = cls.__new__(cls)\n",
    "        self.__dict__.update(model.__dict__)\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, saved_model: bytes | str) -> Self:\n",
    "        if isinstance(saved_model, str) and pathlib.Path(saved_model).exists():\n",
    "            return cls.from_pretrained(fasttext.load_model(saved_model))\n",
    "\n",
    "        if isinstance(saved_model, bytes):\n",
    "            with tempfile.TemporaryDirectory() as d:\n",
    "                model_path = pathlib.Path(d) / cls._tmp_filename\n",
    "                model_path.write_bytes(saved_model)\n",
    "                return cls.load(str(model_path))\n",
    "\n",
    "        raise FileNotFoundError(saved_model)\n",
    "\n",
    "    def serialize(self) -> bytes:\n",
    "        with tempfile.TemporaryDirectory() as d:\n",
    "            model_path = pathlib.Path(d) / self._tmp_filename\n",
    "            self.save_model(str(model_path))\n",
    "            return model_path.read_bytes()\n",
    "\n",
    "    def __reduce__(self) -> tuple[Callable[[bytes | str], Self], tuple[bytes]]:\n",
    "        return self.load, (self.serialize(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc043b8-208e-4f52-babf-ef8e805ab6bf",
   "metadata": {},
   "source": [
    "#### Update our original pipeline with our `PicklableFastText` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1468ff-3e2c-499e-a962-333cdde8788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "picklable_pipeline = pipeline.make_pipeline(\n",
    "    FastTextTransformer(model=PicklableFastText.from_pretrained(fasttext_model)),\n",
    "    cluster.KMeans(n_clusters=2, n_init=\"auto\", random_state=random_state),\n",
    ").fit(cluster_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55037b4-a91f-4ffd-b3b1-b9a1c9755c94",
   "metadata": {},
   "source": [
    "#### Save our new Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642e33d-58d9-4355-8a2a-0491d1d218e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pipeline(picklable_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb28caf-94f9-4195-85de-cf0a4f6d0102",
   "metadata": {},
   "source": [
    "#### Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9305b-3d75-479b-be03-9638b4abf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = lorem.sentence()\n",
    "\n",
    "print(picklable_pipeline.transform([sentence]))\n",
    "print(load_pipeline().transform([sentence]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
